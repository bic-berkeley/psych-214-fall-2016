<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>A worked example of the general linear model &#8212; Functional MRI methods</title>
    
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/copybutton.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="Functional MRI methods" href="index.html" />
    <link rel="next" title="Modeling groups with dummy variables" href="on_dummies_exercise.html" />
    <link rel="prev" title="Understanding least-squares regression" href="on_estimation_solution.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <p><span class="math">\(\newcommand{L}[1]{\| #1 \|}\newcommand{VL}[1]{\L{ \vec{#1} }}\newcommand{R}[1]{\operatorname{Re}\,(#1)}\newcommand{I}[1]{\operatorname{Im}\, (#1)}\)</span></p>
<div class="section" id="a-worked-example-of-the-general-linear-model">
<h1>A worked example of the general linear model<a class="headerlink" href="#a-worked-example-of-the-general-linear-model" title="Permalink to this headline">¶</a></h1>
<p>See: <a class="reference external" href="https://matthew-brett.github.io/teaching/glm_intro.html">introduction to the general linear model</a>.</p>
<p>Here we go through the matrix formulation of the general linear model with the
simplest possible example – a t-test for the difference of the sample mean
from zero.</p>
<p>Let us say we have the hypothesis that men are more psychopathic than women.</p>
<p>We find 10 male-female couples, and we give them each a psychopathy
questionnaire.  We score the questionnaires, and then, for each couple, we
subtract the woman&#8217;s score from the man&#8217;s score, to get a difference score.</p>
<p>We have 10 difference scores:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">#: Our standard imports</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy.linalg</span> <span class="kn">as</span> <span class="nn">npl</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Only show 4 decimals when printing arrays</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">differences</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span> <span class="mf">1.5993</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.13</span>  <span class="p">,</span>  <span class="mf">2.3806</span><span class="p">,</span>  <span class="mf">1.3761</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3595</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="mf">1.0286</span><span class="p">,</span>  <span class="mf">0.8466</span><span class="p">,</span>  <span class="mf">1.6669</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8241</span><span class="p">,</span>  <span class="mf">0.4469</span><span class="p">])</span>
</pre></div>
</div>
<p>Our hypothesis is that the females in the couple have a lower psychopathy
score. We therefore predict that, in the whole population of male-female
couples, the difference measure will, on average, be positive (men have higher
scores than women).</p>
<p>We teat this hypothesis by testing whether the sample mean is far enough from
zero to make it unlikely that the population mean is actually zero.</p>
<div class="section" id="the-standard-error-of-the-mean">
<h2>The standard error of the mean<a class="headerlink" href="#the-standard-error-of-the-mean" title="Permalink to this headline">¶</a></h2>
<p>One way to test this, is to compare the mean value, to the <a class="reference external" href="https://en.wikipedia.org/wiki/Standard_error#Standard_error_of_the_mean_2">standard error of
the mean</a>.</p>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Standard_error">standard error</a> of a statistic (such as a mean) is the standard
deviation of the sampling distribution of the statistic.  The sampling
distribution is the distribution of the statistic that we expect when taking a
very large number of samples of the statistic.  For example, the sampling
distribution of the mean, is the expected distribution of the sample means
generated by taking a very large number of samples.</p>
<p>As usual, define the <em>mean</em> of a vector of values <span class="math">\(\vec{x}\)</span> as:</p>
<div class="math">
\[\bar{x} = \frac{1}{n} \sum_{i=1}^n x_i\]</div>
<p>Define the <em>unbiased estimate of the standard deviation</em> of <span class="math">\(\vec{x}\)</span> as:</p>
<div class="math">
\[s_x = \sqrt{\frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2}\]</div>
<p>Notice the <span class="math">\(\frac{1}{n-1}\)</span>.   We have previously used <span class="math">\(n\)</span> rather than <span class="math">\(n-1\)</span> as
the divisor for the <em>sample standard deviation</em>.  Using <span class="math">\(n\)</span>, our <em>sample
standard deviation</em> is a biased estimate of the population standard deviation.
Using <span class="math">\(n-1\)</span> as the divisor gives an unbiased estimate for population standard
deviation.</p>
<p>The standard error of the mean is:</p>
<div class="math">
\[SE_{\bar{x}} = \frac{s_x}{\sqrt{n}}\]</div>
<p>where <span class="math">\(n\)</span> is the number of samples, 10 in our case.</p>
<p>A t statistic is given by a value divided by the <em>standard error</em> of that
value.  The t statistic for <span class="math">\(\bar{x}\)</span> is:</p>
<div class="math">
\[t = \frac{\bar{x}}{SE_{\bar{x}}}\]</div>
<p>In our case:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">differences</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_bar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_bar</span>
<span class="go">0.70314...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">unviased_var_x</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">x_bar</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">unviased_var_x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s_x</span>
<span class="go">1.17718...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">SEM</span> <span class="o">=</span> <span class="n">s_x</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">SEM</span>
<span class="go">0.37225...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span> <span class="o">=</span> <span class="n">x_bar</span> <span class="o">/</span> <span class="n">SEM</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span>
<span class="go">1.88884...</span>
</pre></div>
</div>
</div>
<div class="section" id="the-standard-error-as-an-estimator">
<h2>The standard error as an estimator<a class="headerlink" href="#the-standard-error-as-an-estimator" title="Permalink to this headline">¶</a></h2>
<p>Imagine that we repeat the following procedure many times, collecting each
value into a vector <span class="math">\(\vec{m}\)</span>:</p>
<ul class="simple">
<li>take <span class="math">\(n\)</span> samples from some distribution;</li>
<li>take the mean of these <span class="math">\(n\)</span> samples.</li>
</ul>
<p>The standard error of the mean is an estimate of the standard deviation of the
values in <span class="math">\(\vec{m}\)</span>.</p>
<p>We can simulate this process when we know the exact distribution of the values
in the population.  For example, let us imagine that we know that the
population distribution is a normal distribution with population mean 10 (<span class="math">\(\mu
= 10\)</span>) and population standard deviation 1.5 (<span class="math">\(\sigma = 1.5\)</span>).</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># 10 samples from normal distribution with mean 5 and sd 1.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sample</span>
<span class="go">array([ 5.7451,  4.7926,  5.9715,  7.2845,  4.6488,  4.6488,  7.3688,</span>
<span class="go">        6.1512,  4.2958,  5.8138])</span>
</pre></div>
</div>
<p>We know the exact mean (<span class="math">\(\mu\)</span>) and standard deviation (<span class="math">\(\sigma\)</span>).  If we draw
a near-infinite number of samples like this, then the standard deviation of
the mean of these samples will be <span class="math">\(\frac{\sigma}{\sqrt{n}}\)</span>:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="mf">1.5</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="go">0.474341...</span>
</pre></div>
</div>
<p>We can compare this number to an estimate of the same thing from a very large
number of means from samples size 10:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">n_samples</span> <span class="o">=</span> <span class="mi">100000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pop_mean</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pop_sd</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">means_of_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">pop_mean</span><span class="p">,</span> <span class="n">pop_sd</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">means_of_samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sq_deviations</span> <span class="o">=</span> <span class="p">(</span><span class="n">means_of_samples</span> <span class="o">-</span> <span class="n">pop_mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># With lots of samples, this value is close to the exact number</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">means_std_dev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">n_samples</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sq_deviations</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">means_std_dev</span>
<span class="go">0.474735...</span>
</pre></div>
</div>
<p>Normally we do not know the exact standard deviation of the population.  The
standard error of the mean is for that situation.  First we use the sample
that we have to get an <em>unbiased estimate</em> of the population standard
deviation:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">sample</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_bar</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">unbiased_var_estimate</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_bar</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">unbiased_sd_est</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">unbiased_var_estimate</span><span class="p">)</span>
</pre></div>
</div>
<p>Of course, this estimate will not be exactly the same as the population
standard deviation (<span class="math">\(\sigma = 1.5\)</span>):</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">unbiased_sd_est</span>
<span class="go">1.433659...</span>
</pre></div>
</div>
<p>We use the unbiased standard deviation estimate to give an unbiased estimate
for the standard error of the mean. This estimate will be close to the
standard deviation of means from many samples of size <span class="math">\(n\)</span>:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Standard deviation of means from population</span>
<span class="gp">&gt;&gt;&gt; </span><span class="mf">1.5</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="go">0.474341...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Our estimate for the standard error of mean</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">unbiased_sd_est</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="go">0.453362...</span>
</pre></div>
</div>
</div>
<div class="section" id="testing-using-the-general-linear-model">
<h2>Testing using the general linear model<a class="headerlink" href="#testing-using-the-general-linear-model" title="Permalink to this headline">¶</a></h2>
<p>It is overkill for us to use the general linear model for this, but it does
show how the machinery works in the simplest case.</p>
<p><span class="math">\(\newcommand{Xmat}{\boldsymbol X} \newcommand{\bvec}{\vec{\beta}}\)</span>
<span class="math">\(\newcommand{\yvec}{\vec{y}} \newcommand{\xvec}{\vec{x}} \newcommand{\evec}{\vec{\varepsilon}}\)</span></p>
<p>The matrix expression of the general linear model is:</p>
<div class="math">
\[\yvec = \Xmat \bvec + \evec\]</div>
<p><span class="math">\(\newcommand{Xmat}{\boldsymbol X} \newcommand{\bvec}{\vec{\beta}}\)</span></p>
<p>Define our design matrix <span class="math">\(\Xmat\)</span> to have a single column of ones:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span>
<span class="go">array([[ 1.],</span>
<span class="go">       [ 1.],</span>
<span class="go">       [ 1.],</span>
<span class="go">       [ 1.],</span>
<span class="go">       [ 1.],</span>
<span class="go">       [ 1.],</span>
<span class="go">       [ 1.],</span>
<span class="go">       [ 1.],</span>
<span class="go">       [ 1.],</span>
<span class="go">       [ 1.]])</span>
</pre></div>
</div>
<p><span class="math">\(\newcommand{\bhat}{\hat{\bvec}} \newcommand{\yhat}{\hat{\yvec}}\)</span></p>
<p><span class="math">\(\bhat\)</span> is The least squares estimate for <span class="math">\(\bvec\)</span>, and is given by:</p>
<div class="math">
\[\bhat = (\Xmat^T \Xmat)^{-1} \Xmat^T \yvec\]</div>
<p>Because <span class="math">\(\Xmat\)</span> is just a column of ones, <span class="math">\(\Xmat^T \yvec = \sum_i{y_i}\)</span>.</p>
<p><span class="math">\(\Xmat^T \Xmat = n\)</span>, so <span class="math">\((\Xmat^T \Xmat)^{-1} = \frac{1}{n}\)</span>.</p>
<p>Thus:</p>
<div class="math">
\[\begin{split}\bhat = (\Xmat^T \Xmat)^{-1} \Xmat^T \yvec \\
= \frac{1}{n} \sum_i{y_i} \\
= \bar{y}\end{split}\]</div>
<p>The student&#8217;s t statistic from the general linear model is:</p>
<div class="math">
\[t = \frac{c^T \hat\beta}{\sqrt{\hat{\sigma}^2 c^T (\Xmat^T \Xmat)^+ c}}\]</div>
<p>where <span class="math">\(\hat{\sigma}^2\)</span> is our estimate of variance in the residuals, <span class="math">\(c\)</span> is a
contrast vector to select some combination of the design columns, and
<span class="math">\((\Xmat^T \Xmat)^+\)</span> is the <em>pseudoinverse</em> of <span class="math">\(\Xmat^T \Xmat\)</span>.</p>
<p>In our case we have only one design column, so <span class="math">\(c = [1]\)</span> and we can omit it.
<span class="math">\(\hat{\sigma}^2 = s_x^2\)</span> for <span class="math">\(s_x\)</span> defined above.  <span class="math">\(\Xmat^T \Xmat\)</span> is
invertible, and we know the inverse already: <span class="math">\(\frac{1}{n}\)</span>.  Therefore:</p>
<div class="math">
\[\begin{split}t = \frac{\bar{y}}{s_x \sqrt{\frac{1}{n}}} \\
= \bar{y} \Big/ \frac{s_x}{\sqrt{n}} \\
= \frac{\bar{y}}{SE_{\bar{y}}}\end{split}\]</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">PSYCH 214 Fall 2016</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="syllabus.html">Syllabus</a></li>
<li class="toctree-l1"><a class="reference internal" href="preparation.html">Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="logistics.html">Logistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="classes.html">Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="labs.html">Labs</a></li>
<li class="toctree-l1"><a class="reference internal" href="projects.html">Projects</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics.html">Course material by topic</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_data.html">Example datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">Bibliography</a></li>
</ul>


<hr />
<ul>
    
    <li class="toctree-l1"><a href="_downloads">Website downloads</a></li>
    
    <li class="toctree-l1"><a href="https://nipy.bic.berkeley.edu/psych-214">Dataset downloads</a></li>
    
    <li class="toctree-l1"><a href="https://github.com/psych-214-fall-2016">Github organization</a></li>
    
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="on_estimation_solution.html" title="previous chapter">Understanding least-squares regression</a></li>
      <li>Next: <a href="on_dummies_exercise.html" title="next chapter">Modeling groups with dummy variables</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2016, Matthew Brett, JB Poline.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.4.6</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.9</a>
      
      |
      <a href="_sources/mean_test_example.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>